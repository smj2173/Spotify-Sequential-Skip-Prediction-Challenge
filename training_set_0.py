# -*- coding: utf-8 -*-
"""training_set_0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c4-xeeaY6y95Dm6OtaN4AowbvmmEQuDI
"""

#Downloads Training Set
#runtime about 3 minutes
!wget https://os.zhdk.cloud.switch.ch/swift/v1/crowdai-public/spotify-sequential-skip-prediction-challenge/split-files/training_set_0.tar.gz

!tar -xvf 'training_set_0.tar.gz'
#Untars the dataset 
#runtime about 4 minutes

#This code block aims to find the Pearson's coefficient measure of correlation between skip1, skip2, and skip3, and the data values 
#of context_switch, no_pause_before_play, long_pause_before_play, premium, session_position, and hour_of_day
#runtime = about 10 minutes

import pandas as pd 
import os
from scipy.stats import pearsonr
dir = '/content/training_set/'

skip1_context_switch, skip2_context_switch, skip3_context_switch = {}, {}, {}
skip1_nopause, skip2_nopause, skip3_nopause = {}, {}, {}
skip1_prem, skip2_prem, skip3_prem = {}, {}, {}
skip1_hour, skip2_hour, skip3_hour = {}, {}, {}
skip1_ses_pos, skip2_ses_pos, skip3_ses_pos = {}, {}, {}
skip1_longpause, skip2_longpause, skip3_longpause = {}, {}, {}

def find_correlations(file_name, data):
  (data["skip_1"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_2"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_3"]).replace([False, True],[0, 1], inplace=True)
  (data["premium"]).replace([False, True],[0, 1], inplace=True)

  #correlation between context_switch and skips
  skip1_context_switch[file_name] = pearsonr(data["context_switch"], data["skip_1"])
  print(skip1_context_switch)
  skip2_context_switch[file_name] = pearsonr(data["context_switch"], data["skip_2"])
  skip3_context_switch[file_name] = pearsonr(data["context_switch"], data["skip_3"])

  #correlation between no_pause_before_play and skips
  skip1_nopause[file_name] = pearsonr(data["no_pause_before_play"], data["skip_1"])
  skip2_nopause[file_name] = pearsonr(data["no_pause_before_play"], data["skip_2"])
  skip3_nopause[file_name] = pearsonr(data["no_pause_before_play"], data["skip_3"])

  #correlation between long_pause_before_play and skips
  skip1_longpause[file_name] = pearsonr(data["long_pause_before_play"], data["skip_1"])
  skip2_longpause[file_name] = pearsonr(data["long_pause_before_play"], data["skip_2"])
  skip3_longpause[file_name] = pearsonr(data["long_pause_before_play"], data["skip_3"])

  #correlation between session_position and skips
  skip1_ses_pos[file_name] = pearsonr(data["session_position"], data["skip_1"])
  skip2_ses_pos[file_name] = pearsonr(data["session_position"], data["skip_2"])
  skip3_ses_pos[file_name] = pearsonr(data["session_position"], data["skip_3"])

  #correlation between premium and skips
  skip1_prem[file_name] = pearsonr(data["premium"], data["skip_1"])
  skip2_prem[file_name] = pearsonr(data["premium"], data["skip_2"])
  skip3_prem[file_name] = pearsonr(data["premium"], data["skip_3"])

  #correlation between hour_of_day and skips
  skip1_hour[file_name] = pearsonr(data["hour_of_day"], data["skip_1"])
  skip2_hour[file_name] = pearsonr(data["hour_of_day"], data["skip_2"])
  skip3_hour[file_name] = pearsonr(data["hour_of_day"], data["skip_3"])

for file in os.listdir(dir):
  if file.endswith(".csv"):
    find_correlations(file, pd.read_csv('/content/training_set/'+file))



#Analyses
#Outputs the Pearson's Coefficient Value for skip1, skip2, skip3 and the respective dataset variables

#context_switch

temp_context = [list(ele) for ele in skip1_context_switch.values()]
print(temp_context)
mean_skip1_context = sum(i[0] for i in temp_context) / len(skip1_context_switch)
print("mean pearson's value correlation between skip1 and context_switch %.3f" % mean_skip1_context)
p_1 = sum(i[1] for i in temp_context) / len(skip1_context_switch)
print("mean p-value %.3f" % p_1)

temp_context2 = [list(ele) for ele in skip2_context_switch.values()]
mean_skip2_context = sum(i[0] for i in temp_context2) / len(skip2_context_switch)
print("mean pearson's value correlation between skip2 and context_switch %.3f" % mean_skip2_context)
p_2 = sum(i[1] for i in temp_context2) / len(skip2_context_switch)
print("mean p-value %.3f" % p_2)

temp_context3 = [list(ele) for ele in skip3_context_switch.values()]
mean_skip3_context = sum(i[0] for i in temp_context3) / len(skip3_context_switch)
print("mean pearson's  correlation between skip3 and context_switch %.3f" % mean_skip3_context)
p_3 = sum(i[1] for i in temp_context3) / len(skip3_context_switch)
print("mean p-value %.3f" % p_3)

#no_pause_before_play
temp_no1 = [list(ele) for ele in skip1_nopause.values()]
mean_skip1_no_pause = sum(i[0] for i in temp_no1) / len(skip1_nopause)
print("mean pearson's correlation between skip1 and no_pause_before_play: %.3f" % mean_skip1_no_pause)
p_1_2 = sum(i[1] for i in temp_no1) / len(skip1_nopause)
print("mean p-value %.3f" % p_1_2)

temp_no2 = [list(ele) for ele in skip2_nopause.values()]
mean_skip2_no_pause = sum(i[0] for i in temp_no2) / len(skip2_nopause)
print("mean pearson's correlation between skip2 and no_pause_before_play: %.3f" % mean_skip2_no_pause)
p_2_2 = sum(i[1] for i in temp_no2) / len(skip2_nopause)
print("mean p-value %.3f" % p_2_2)

temp_no3 = [list(ele) for ele in skip3_nopause.values()]
mean_skip3_no_pause = sum(i[0] for i in temp_no3) / len(skip3_nopause)
print("mean pearson's correlation between skip3 and no_pause_before_play: %.3f" % mean_skip3_no_pause)
p_3_2 = sum(i[1] for i in temp_no3) / len(skip3_nopause)
print("mean p-value %.3f" % p_3_2)

#premium
temp_prem = [list(ele) for ele in skip1_prem.values()]
mean_skip1_prem = sum(i[0] for i in temp_prem) / len(skip1_prem)
print("mean pearson's correlation between skip1 and premium %.3f" % mean_skip1_prem)
p_1_3 = sum(i[1] for i in temp_prem) / len(skip1_prem)
print("mean p-value %.3f" % p_1_3)

temp_prem2 = [list(ele) for ele in skip2_prem.values()]
mean_skip2_prem = sum(i[0] for i in temp_prem2) / len(skip2_prem)
print("mean pearson's correlation between skip2 and premium %.3f" % mean_skip2_prem)
p_2_3 = sum(i[1] for i in temp_prem2) / len(skip2_prem)
print("mean p-value %.3f" % p_1_2)

temp_prem3 = [list(ele) for ele in skip3_prem.values()]
mean_skip3_prem = sum(i[0] for i in temp_prem3) / len(skip3_prem)
print("mean pearson correlation between skip3 and premium %.3f" % mean_skip3_prem)
p_3_3 = sum(i[1] for i in temp_prem3) / len(skip3_prem)
print("mean p-value %.3f" % p_3_2)

#hour_of_day
temp_hour = [list(ele) for ele in skip1_hour.values()]
mean_skip1_hour = sum(i[0] for i in temp_hour) / len(skip1_hour)
print("mean pearson correlation between skip1 and hour of day %.3f" % mean_skip1_hour)
p_1_4 = sum(i[1] for i in temp_hour) / len(skip1_hour)
print("mean p-value %.3f" % p_1_4)

temp_hour2 = [list(ele) for ele in skip2_hour.values()]
mean_skip2_hour = sum(i[0] for i in temp_hour2) / len(skip2_hour)
print("mean pearson correlation between skip2 and hour of day %.3f" % mean_skip2_hour)
p_2_4 = sum(i[1] for i in temp_hour2) / len(skip2_hour)
print("mean p-value %.3f" % p_2_4)

temp_hour3 = [list(ele) for ele in skip3_hour.values()]
mean_skip3_hour = sum(i[0] for i in temp_hour3) / len(skip3_hour)
print("mean pearson correlation between skip3 and hour of day %.3f" % mean_skip3_hour)
p_3_4 = sum(i[1] for i in temp_hour3) / len(skip3_hour)
print("mean p-value %.3f" % p_3_4)

#session_position
temp_ses = [list(ele) for ele in skip1_ses_pos.values()]
mean_skip1_ses_pos = sum(i[0] for i in temp_ses) / len(skip1_ses_pos)
print("mean pearson correlation between skip1 and session position %.3f" % mean_skip1_ses_pos)
p_1_5 = sum(i[1] for i in temp_ses) / len(skip1_ses_pos)
print("mean p-value %.3f" % p_1_5)

temp_ses2 = [list(ele) for ele in skip2_ses_pos.values()]
mean_skip2_ses_pos = sum(i[0] for i in temp_ses2) / len(skip2_ses_pos)
print("mean pearson correlation between skip2 and session position %.3f" % mean_skip2_ses_pos)
p_2_5 = sum(i[1] for i in temp_ses2) / len(skip2_ses_pos)
print("mean p-value %.3f" % p_2_5)

temp_ses3 = [list(ele) for ele in skip3_ses_pos.values()]
mean_skip3_ses_pos = sum(i[0] for i in temp_ses3) / len(skip3_ses_pos)
print("mean pearson correlation between skip3 and session position %.3f" % mean_skip3_ses_pos)
p_3_5 = sum(i[1] for i in temp_ses3) / len(skip3_ses_pos)
print("mean p-value %.3f" % p_3_5)

#long_pause_before_play
temp_long = [list(ele) for ele in skip1_longpause.values()]
mean_skip1_longpause = sum(i[0] for i in temp_long) / len(skip1_longpause)
print("mean pearson correlation between skip1 and long pause before play %.3f" % mean_skip1_longpause)
p_1_6 = sum(i[1] for i in temp_long) / len(skip1_longpause)
print("mean p-value %.3f" % p_1_6)

temp_long2 = [list(ele) for ele in skip2_longpause.values()]
mean_skip2_longpause = sum(i[0] for i in temp_long2) / len(skip2_longpause)
print("mean pearson correlation between skip2 and long pause before play %.3f" % mean_skip2_longpause)
p_2_6 = sum(i[1] for i in temp_long2) / len(skip2_longpause)
print("mean p-value %.3f" % p_2_6)

temp_long3 = [list(ele) for ele in skip3_longpause.values()]
mean_skip3_longpause = sum(i[0] for i in temp_long3) / len(skip2_longpause)
print("mean pearson correlation between skip3 and long pause before play %.3f" % mean_skip3_longpause)
p_3_6 = sum(i[1] for i in temp_long3) / len(skip3_longpause)
print("mean p-value %.3f" % p_3_6)

#runtime = about 15 minutes
import pandas as pd 
import os
from scipy.stats import pearsonr
dir = '/content/training_set/'

skip1_length, skip2_length, skip3_length = {}, {}, {}
skip1_seekfwd, skip2_seekfwd, skip3_seekfwd = {}, {}, {}
skip1_seekback, skip2_seekback, skip3_seekback = {}, {}, {}
skip1_shuffle, skip2_shuffle, skip3_shuffle = {}, {}, {}

def find_more_correlations(file_name, data):
  (data["skip_1"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_2"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_3"]).replace([False, True],[0, 1], inplace=True)
  (data["hist_user_behavior_is_shuffle"]).replace([False, True], [0,1], inplace=True)

  #correlation between session_length and skips
  skip1_length[file_name] = pearsonr(data["session_length"], data["skip_1"])
  skip2_length[file_name] = pearsonr(data["session_length"], data["skip_2"])
  skip3_length[file_name] = pearsonr(data["session_length"], data["skip_3"])

  #correlation between seekfwd and skips
  skip1_seekfwd[file_name] = pearsonr(data["hist_user_behavior_n_seekfwd"], data["skip_1"])
  skip2_seekfwd[file_name] = pearsonr(data["hist_user_behavior_n_seekfwd"], data["skip_2"])
  skip3_seekfwd[file_name] = pearsonr(data["hist_user_behavior_n_seekfwd"], data["skip_3"])

  #correlation between seekback and skips
  skip1_seekback[file_name]  = pearsonr(data["hist_user_behavior_n_seekback"], data["skip_1"])
  skip2_seekback[file_name] = pearsonr(data["hist_user_behavior_n_seekback"], data["skip_2"])
  skip3_seekback[file_name] = pearsonr(data["hist_user_behavior_n_seekback"], data["skip_3"])

  #correlation between is_shuffle and skips
  skip1_shuffle[file_name] = pearsonr(data["hist_user_behavior_is_shuffle"], data["skip_1"])
  skip2_shuffle[file_name] = pearsonr(data["hist_user_behavior_is_shuffle"], data["skip_2"])
  skip3_shuffle[file_name] = pearsonr(data["hist_user_behavior_is_shuffle"], data["skip_3"])

for file in os.listdir(dir):
  if file.endswith(".csv"):
    find_more_correlations(file, pd.read_csv('/content/training_set/'+file))


#session_length
temp_len = [list(ele) for ele in skip1_length.values()]
mean_skip1_length = sum(i[0] for i in temp_len) / len(skip1_length)
print("mean pearson correlation between skip1 and session length %.3f" % mean_skip1_length)
p_a = sum(i[1] for i in temp_len) / len(skip1_length)
print("mean p-value %.3f" % p_a)

temp_len2 = [list(ele) for ele in skip2_length.values()]
mean_skip2_length = sum(i[0] for i in temp_len2) / len(skip2_length)
print("mean pearson correlation between skip2 and session length %.3f" % mean_skip2_length)
p_b = sum(i[1] for i in temp_len2) / len(skip2_length)
print("mean p-value %.3f" % p_b)

temp_len3 = [list(ele) for ele in skip3_length.values()]
mean_skip3_length = sum(i[0] for i in temp_len3) / len(skip3_length)
print("mean pearson correlation between skip3 and session length %.3f" % mean_skip3_length)
p_c = sum(i[1] for i in temp_len3) / len(skip3_length)
print("mean p-value %.3f" % p_c)

#seekfwd
temp_fwd = [list(ele) for ele in skip1_seekfwd.values()]
mean_skip1_seekfwd = sum(i[0] for i in temp_fwd) / len(skip1_seekfwd)
print("mean pearson correlation between skip1 and history user behavior seek fwd %.3f" % mean_skip1_seekfwd)
p_d = sum(i[1] for i in temp_fwd) / len(skip1_seekfwd)
print("mean p-value %.3f" % p_d)

temp_fwd2 = [list(ele) for ele in skip2_seekfwd.values()]
mean_skip2_seekfwd = sum(i[0] for i in temp_fwd2) / len(skip2_seekfwd)
print("mean pearson correlation between skip2 and history user behavior seek fwd %.3f" % mean_skip2_seekfwd)
p_e = sum(i[1] for i in temp_fwd2) / len(skip2_seekfwd)
print("mean p-value %.3f" % p_e)

temp_fwd3 = [list(ele) for ele in skip3_seekfwd.values()]
mean_skip3_seekfwd = sum(i[0] for i in temp_fwd3) / len(skip3_seekfwd)
print("mean pearson correlation between skip3 and history user behavior seek fwd %.3f" % mean_skip3_seekfwd)
p_f = sum(i[1] for i in temp_fwd3) / len(skip3_seekfwd)
print("mean p-value %.3f" % p_f)

#seekback
temp_back = [list(ele) for ele in skip1_seekback.values()]
mean_skip1_seekback = sum(i[0] for i in temp_back) / len(skip1_seekback)
print("mean pearson correlation between skip1 and history user behavior of seek back %.3f" % mean_skip1_seekback)
p_g = sum(i[1] for i in temp_back) / len(skip1_seekback)
print("mean p-value %.3f" % p_g)

temp_back2 = [list(ele) for ele in skip2_seekback.values()]
mean_skip2_seekback = sum(i[0] for i in temp_back2) / len(skip2_seekback)
print("mean pearson correlation between skip2 and history user behavior seek back %.3f" % mean_skip2_seekback)
p_h = sum(i[1] for i in temp_back2) / len(skip2_seekback)
print("mean p-value %.3f" % p_h)

temp_back3 = [list(ele) for ele in skip3_seekback.values()]
mean_skip3_seekback = sum(i[0] for i in temp_back3) / len(skip3_seekback)
print("mean pearson correlation between skip3 and history user behavior of seek back %.3f" % mean_skip3_seekback)
p_i = sum(i[1] for i in temp_back3) / len(skip3_seekback)
print("mean p-value %.3f" % p_i)

#is_shuffle
temp_shuffle = [list(ele) for ele in skip1_shuffle.values()]
mean_skip1_shuffle = sum(i[0] for i in temp_shuffle) / len(skip1_shuffle)
print("mean pearson correlation between skip1 and is shuffle %.3f" % mean_skip1_shuffle)
p_j = sum(i[1] for i in temp_shuffle) / len(skip1_shuffle)
print("mean p-value %.3f" % p_j)

temp_shuffle2 = [list(ele) for ele in skip2_shuffle.values()]
mean_skip2_shuffle = sum(i[0] for i in temp_shuffle2) / len(skip2_shuffle)
print("mean pearson correlation between skip2 and is shuffle %.3f" % mean_skip2_shuffle)
p_k = sum(i[1] for i in temp_shuffle2) / len(skip2_shuffle)
print("mean p-value %.3f" % p_k)

temp_shuffle3 = [list(ele) for ele in skip3_shuffle.values()]
mean_skip3_shuffle = sum(i[0] for i in temp_shuffle3) / len(skip3_shuffle)
print("mean pearson correlation between skip3 and is shuffle %.3f" % mean_skip3_shuffle)
p_l = sum(i[1] for i in temp_shuffle3) / len(skip3_shuffle)
print("mean p-value %.3f" % p_l)

#this code block aims to find the Pearson's Coefficient for Particularly the Context-Type Data

dir = '/content/training_set/'
import pandas as pd 
import os
from scipy.stats import pearsonr

skip1_context, skip2_context, skip3_context = {}, {}, {}

def correlation_context_type(file_name, data):
  (data["skip_1"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_2"]).replace([False, True],[0, 1], inplace=True)
  (data["skip_3"]).replace([False, True],[0, 1], inplace=True)

  (data["context_type"]).replace(["radio", "editorial_playlist", "catalog", "user_collection", "personalized_playlist", "charts"],[0, 1, 2, 3, 4, 5], inplace=True)

  skip1_context[file_name] = pearsonr(data["context_type"], data["skip_1"])
  skip2_context[file_name] = pearsonr(data["context_type"], data["skip_2"])
  skip3_context[file_name] = pearsonr(data["context_type"], data["skip_3"])


for file in os.listdir(dir):
  if file.endswith(".csv"):
    correlation_context_type(file, pd.read_csv('/content/training_set/'+file))

context = [list(ele) for ele in skip1_context.values()]
mean_skip1_context = sum(i[0] for i in context) / len(skip1_context)
print("mean pearson correlation between skip1 and context type %.3f" % mean_skip1_context)
p_a = sum(i[1] for i in context) / len(skip1_context)
print("mean p-value %.3f" % p_a)

context2 = [list(ele) for ele in skip2_context.values()]
mean_skip2_context = sum(i[0] for i in context2) / len(skip2_context)
print("mean pearson correlation between skip2 and context type %.3f" % mean_skip2_context)
p_b = sum(i[1] for i in context2) / len(skip2_context)
print("mean p-value %.3f" % p_b)

context3 = [list(ele) for ele in skip3_context.values()]
mean_skip3_context = sum(i[0] for i in context3) / len(skip3_context)
print("mean pearson correlation between skip3 and context type %.3f" % mean_skip3_context)
p_c = sum(i[1] for i in context3) / len(skip3_context)
print("mean p-value %.3f" % p_c)

dir = '/content/training_set/'
bar1 = {"catalog" : 0, "editorial_playlist" : 0, "radio" : 0, "user_collection" : 0, "personalized_playlist" : 0, "charts":0}
bar2 = {"catalog" : 0, "editorial_playlist" : 0, "radio" : 0, "user_collection" : 0, "personalized_playlist" : 0, "charts":0}
bar3 = {"catalog" : 0, "editorial_playlist" : 0, "radio" : 0, "user_collection" : 0, "personalized_playlist" : 0, "charts":0}
import matplotlib.pyplot as plt

#Helper Method to gather the frequency of context_type respective to skip1, skip2, skip3 being positive
def bar_graph(data):
    (data["skip_1"]).replace([False, True],[0, 1], inplace=True)
    (data["skip_2"]).replace([False, True],[0, 1], inplace=True)
    (data["skip_3"]).replace([False, True],[0, 1], inplace=True)
    
    #FREQUENCY OF CONTEXT_TYPE RESPECTIVE TO SKIP_1 IS TRUE
    df_1 = (data.groupby(['skip_1', 'context_type']).size()).reset_index(name='count')
    bar1["catalog"] += df_1.at[6, 'count'] #catalog frequency
    bar1["charts"] += df_1.at[7, 'count'] #charts frequency
    bar1["editorial_playlist"] += df_1.at[8, 'count'] #editorial frequency 
    bar1["personalized_playlist"] += df_1.at[9, 'count'] #personalized playlist frequency
    bar1["radio"] += df_1.at[10, 'count'] #radio frequency
    bar1["user_collection"] += df_1.at[11, 'count'] #user_collection frequency

    #FREQUENCY OF CONTEXT_TYPE RESPECTIVE TO SKIP_2 IS TRUE
    df_2 = data.groupby(['skip_2', 'context_type']).size().reset_index(name='count')
    bar2["catalog"] += df_1.at[6, 'count'] 
    bar2["charts"] += df_1.at[7, 'count']
    bar2["editorial_playlist"] += df_1.at[8, 'count']
    bar2["personalized_playlist"] += df_1.at[9, 'count']
    bar2["radio"] += df_1.at[10, 'count']
    bar2["user_collection"] += df_1.at[11, 'count']

    #FREQUENCY OF CONTEXT_TYPE RESPECTIVE TO SKIP_3 IS TRUE
    df_3 = data.groupby(['skip_1', 'context_type']).size().reset_index(name='count')
    bar3["catalog"] += df_1.at[6, 'count']
    bar3["charts"] += df_1.at[7, 'count']
    bar3["editorial_playlist"] += df_1.at[8, 'count']
    bar3["personalized_playlist"] += df_1.at[9, 'count']
    bar3["radio"] += df_1.at[10, 'count']
    bar3["user_collection"] += df_1.at[11, 'count']

for file in os.listdir(dir):
  if file.endswith(".csv"):
    bar_graph(pd.read_csv('/content/training_set/'+file))


f = plt.figure()
f.set_figwidth(15)
f.set_figheight(10)
plt.bar(bar1.keys(), bar1.values())
plt.title("Positive Skip_1 Value Context_Type Breakdown")
plt.xlabel("Context Type")
plt.ylabel("Frequency")
plt.show()


f = plt.figure()
f.set_figwidth(15)
f.set_figheight(10)
plt.bar(bar2.keys(), bar2.values())
plt.title("Positive Skip_2 Value Context_Type Breakdown")
plt.xlabel("Context Type")
plt.ylabel("Frequency")
plt.show()


f = plt.figure()
f.set_figwidth(15)
f.set_figheight(10)
plt.bar(bar3.keys(), bar3.values())
plt.title("Positive Skip_3 Value Context_Type Breakdown")
plt.xlabel("Context Type")
plt.ylabel("Frequency")
plt.show()

"""Questions I have for our analyses:


*   Which skip value are we correlating variables to (skip_1, skip_2, skip_3) -> I would guess we want to && them and see if at least one of them is true, unless we want to break our analysis into predicting they will skip in skip_1, skip_2, or skip_3 (i.e. what part of the song)
*   examples of variables we can easily correlate: time of day (in hr), session _position (track # in session), premium (have unlimited # of skips), context_type, etc. 
*   Code terribly inefficient right now, which is difficult for testing purposes




"""



# @title Models